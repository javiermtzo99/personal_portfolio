---
title: Data Engineering
order: 1
icon: fas fa-database
short: Building modern big data pipelines and workflows.
---

With more than two years of experience in data engineering, I build modern big-data pipelines and workflows with a wide range of technologies.

My background includes:
- Building ETL/ELT pipelines across diverse platforms and frameworks
- Deploying and operating data platforms on AWS (S3, Glue, Athena, Lambda, etc)
- Orchestrating distributed workloads with PySpark and Airflow
- Developing high-quality Kafka producers and consumers
- Designing efficient warehouses and query systems on Snowflake and other modern OLAP tools
- Creating stakeholder-focused visualizations in AWS QuickSight, Grafana, Dash, and Streamlit
- Setting up CI/CD pipelines to automate and safeguard data workflows

What sets me apart is not just my technical toolkit but my commitment to continuous learning and adaptability. Whether I’m defining data contracts, extending CI/CD practices, or adopting new architectural patterns, I pursue the most effective solution for each challenge. I’m especially driven to deliver end-to-end data solutions that maximize business value.